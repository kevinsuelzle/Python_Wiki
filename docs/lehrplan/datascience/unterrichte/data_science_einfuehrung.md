# Einf√ºhrung in Data Science 

[//]: # ([10 min])

<details>
<summary>
üé¶ Video
</summary>
<iframe width="560" height="315" src="https://www.youtube.com/embed/8rGP5ErEKOU?si=thReMME17WkPEXzL" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</details>

Was ist Data Science?

Der amerikanische Zukunftsforscher John Naisbitt hat 1982 ein Buch namens "Megatrends" ver√∂ffentlicht, das √ºber 14 Millionen Mal verkauft wurde. In dem Buch beschrieb Naisbitt einen wichtigen Trend, den er schon damals erkannte. Unsere Gesellschaften entwickeln sich in Richtung Informationsgesellschaften und sammeln dabei immer mehr Informationen bzw. Daten. Und irgendwann sah Naisbitt folgende Situation auf uns zukommen:

    "Wir ertrinken in Daten, aber hungern doch nach Wissen" (John Naisbitt, 1982)

Genau hier setzt Data Science an. Data Science ist ein Bereich, bei dem wir mittels Statistik, Visualisierungen und Machine Learning (zu diesen Begriffen sp√§ter mehr!) versuchen aus riesigen Mengen von Zahlen das zu generieren, was uns wirklich interessiert: *Wissen* (neue Erkenntnisse, neue Einsichten).

Um es kurz zu machen: Data Science ist ein Prozess, der aus Daten Wissen generiert.

```mermaid
graph LR;
    D(Daten) --> B["DATA SCIENCE"] --> W(Wissen)
```

# Der Data Science Prozess 

[//]: # ([20 min])

Die Frage ist, ob man diesen Prozess ("mache aus Daten neues Wissen") irgendwie als einen Standardprozess formulieren kann. Hierzu gibt es verschiedene Data Science Prozess Modelle. Das vielleicht bekannteste Data Science Prozess Modell ist das *CRISP-DM* Prozess Modell.

Wof√ºr steht diese kryptische Abk√ºrzung?

*CRISP-DM* steht hierbei f√ºr *Cross Industry Standard Process for Data Mining*, also auf Deutsch ein Industrie-√ºbergreifender Standardprozess f√ºr das Data Mining. Was ist jetzt schon wieder *Data Mining*? Dieser Begriff meint im Wesentliche das Gleiche wie *Data Science* war aber fr√ºher verbreiteter. Heute reden alle nur noch von *Data Science* und keiner mehr von *Data Mining*.

Das CRISP-DM Data Science Prozessmodell umfasst dabei folgende sechs Phasen:

| Phase | Name der Phase             | Beschreibung                                                                                         |
|----|----------------------------|------------------------------------------------------------------------------------------------------|
|1| Gesch√§ftsverst√§ndnis       | Verstehen der Projektziele und Anforderungen aus gesch√§ftlicher Sicht. Entwicklung eines Projektplans.|
|2| Datenverst√§ndnis           | Sammeln der Daten, Identifizierung der Datenqualit√§t, Erkundung der Datenstrukturen und Inhalte.     |
|3| Datenvorbereitung          | Bereinigung und Transformation der Daten f√ºr die Analyse. Erstellung von Datens√§tzen zum Modellieren. |
|4| Modellierung               | Auswahl und Anwendung verschiedener Modellierungstechniken. Kalibrierung der Modellparameter.        |
|5| Bewertung                  | Bewertung der Modelle, um sicherzustellen, dass sie den Gesch√§ftszielen entsprechen.                  |
|6| Bereitstellung             | Planung der Bereitstellung der Modelle, Erstellung von Berichten, Finalisierung des Modells f√ºr die Praxis.       |


# Ein Data Science Beispiel [45 min]

War dir das zu abstrakt? Hier ist ein konkretes echtes Beispiel aus der Praxis!

Die Firma Rossmann hat vor einigen Jahren auf der Webseite Kaggle einen Wettbewerb ausgerufen:

[Rossmann Store Sales - Forecast sales using store, promotion, and competitor data](https://www.kaggle.com/c/rossmann-store-sales)

Es ging um folgende Situation: die Firma Rossmann hat in Deutschland 1115 Filialen. Jeder Leiter muss f√ºr die Personalplanung vorplanen wieviele Mitarbeiter er in den n√§chsten Tagen und Wochen (beispielsweise an den Kassen) einplant. Das h√§ngt wiederum davon ab, wieviel in der Filiale los sein wird.

Daher hat die Firma Rossmann die Anzahl der gekauften Produkte und die Anzahl der Kunden √ºber einen l√§ngeren Zeitraum (2.5 Jahre) f√ºr jede der 1115 Filialen ver√∂ffentlicht. Die Anzahl der gekauften Produkte und die Anzahl der Kunden (jeweils pro Tag) √ºber diese 2.5 Jahre ist jeweils eine lange Zeitreihe. Die Hoffnung war, dass man aus solchen Zeitreihen etwas √ºber die Verk√§ufe und die Kundenanzahlen in den n√§chsten sechs Wochen sagen k√∂nnte.

Der CRISP-DM Data Science Prozess kann nun hierbei so aussehen:

*1. Gesch√§ftsverst√§ndnis:* Ein Data Scientist versucht genau dieses Problem in der Diskussion mit der Gesch√§ftsleitung zu verstehen und definiert zusammen mit der Gesch√§ftsleitung das Ziel bzw. die Ziele des Projektes: Wir wollen die Anzahl der Kunden und verkauften Produkte in der Zukunft (kommenden 6 Wochen) vorhersagen k√∂nnen. Mehrwert dann: wir k√∂nnen die Personalplanung besser durchf√ºhren.

*2. Datenverst√§ndnis:* Der Data Scientist informiert sich welche Daten es gibt. Hier sind es beispielsweise historische Daten (der letzten 2.5 Jahre) √ºber die Anzahl der Kunden und der Anzahl der verkauften Produkte auf Tagesbasis. Der Data Scientist √ºberpr√ºft die *Datenqualit√§t*: Liegen die Daten  wirklich f√ºr alle 1115 Filialen durchgehend vor oder gibt es L√ºcken in den Daten? Gibt es vielleicht Fehler in den Daten (negative Verkaufszahlen, unm√∂gliche hohe Kundenanzahlen pro Tag)?

*3. Datenvorbereitung:* Der Data Scientist "bereinigt" die Daten. Beispielsweise interpoliert er fehlende Werte durch den letzten und den n√§chsten vorhandenen Wert. Eventuell tr√§gt er auch Daten aus verschiedenen Quellen in ein einheitliches Format, um die nachfolgende Analyse einfacher zu machen. Beispielsweise k√∂nnten einige Zeitreihen als .xlsx Dateien vorliegen, andere als .csv Dateien. Er k√∂nnte dann ein Python-Skript schreiben, das √ºber alle Dateien l√§uft, diese einliest und als eine einzige gro√üe .csv Datei speichert.

*4. Modellierung:* Wir w√ºnschen uns ein Modell, das auf Basis der Auslastung einer Filiale in der Vergangenheit die Auslastung der Filiale in der Zukunft vorhersagen kann. Sehr beliebt ist heute in dieser Phase das Machine Learning. Dabei programmieren wir nicht ein, wie ein Computer diese Aufgabe l√∂sen soll, sondern zeigen dem Computer einfach Beispiele (x,y):

        x = (Anzahl Kunden vor 14 Tagen, Anzahl Kunden vor 13 Tagen , ..., Anzahl Kunden gestern)
        
        y = (Anzahl Kunden morgen, Anzahl Kunden in 2 Tagen, ..., Anzahl Kunden in 6 Wochen)
                                           
und Machine Learning Algorithmen versuchen dann den Zusammenhang zwischen x und y zu erlernen und liefern ein Modell zur√ºck, dass bei Eingabe von x dann y zur√ºckgibt:

```mermaid
graph LR;
    x([x]) --> Modell --> y([y])
```

Ein kleiner Hinweis: es muss aber nicht immer Machine Learning sein!

Manchmal kann man auch durch einfache Visualisierungen bereits klare Muster in den Daten erkennen, die man in die Zukunft fortsetzen kann. Zum Beispiel k√∂nnten wir auch durch eine tagesweise Mittelung der Kundenanzahlen (Montage-Samstage) sehen, dass es ein typisches wochenweises Auslastungsmuster √ºber der Zeit gibt, das wir dann einfach f√ºr die Auslastungsvorhersage nehmen k√∂nnten - ganz ohne Machine Learning.

*5. Bewertung:* Meistens erstellt ein Data Scientist nicht nur ein Modell, sondern probiert mehrere Modelle aus. Jedes Modell wird dann auf sogenannten Testdaten getestet, wie gut es funktioniert. Hier w√§re der Test beispielsweise wie gut das Modell die Anzahl der Kunden in den n√§chsten Wochen vorhersagen kann. Das beste Modell k√∂nnte dann ausgew√§hlt werden.

*6. Bereitstellung:* Wenn das beste Modell auf dem Computer des Data Scientist liegt, bringt es der Firma nicht viel. Es soll ja von den Filialleitern zur Personalplanung genutzt werden k√∂nnnen. Daher muss es diesen auch zur Verf√ºgung gestellt werden. Zum Beispiel k√∂nnte das Modell auf einem eigenen Server gehostet werden. Die Filialleiter k√∂nnten dann √ºber ein Webinterface die Auslastung der vergangenen Wochen eingeben. Das Webinterface reicht diese Zahlen x dann an ein Python-Skript weiter, dass das Modell einliest und die Vorhersage y berechnet. Diese Vorhersage wird dann abschlie√üend √ºber ein dynamisches Webinterface dem Filialleiter ausgegeben.

# Das Python-√ñkosystem f√ºr Data Science [15 min]

Python ist auch so beliebt, weil es so unglaublich viele hilfreiche Module f√ºr alle m√∂glichen Aufgaben gibt. Wenn du ein Modul mit `pip install <Modulname>` installierst, kommen diese normalerweise vom *Python Package Index* (kurz: *PyPI*) https://pypi.org/. Und dort finden sich aktuell fast eine halbe Millionen Module!

F√ºr die Analyse von Daten mit Python sind dabei vor allem folgende vier Module wichtig:

| Modulname    | Projektwebseite                                          | Wozu brauche ich das?                                                                               |
|--------------|----------------------------------------------------------|-----------------------------------------------------------------------------------------------------|
| Pandas       | [https://pandas.pydata.org](https://pandas.pydata.org)   | Das ist quasi das "Excel f√ºr Python"                                                                |
| Matplotlib   | [https://matplotlib.org](https://matplotlib.org)         | Erzeugung beliebiger Diagramme                                                                      |
| Seaborn      | [https://seaborn.pydata.org](https://seaborn.pydata.org) | Baut direkt auf Matplotlib auf, um Statistikplots einfacher als Matplotlib zur Verf√ºgung zu stellen |
| Scikit-learn | [https://scikit-learn.org](https://scikit-learn.org)     | Enth√§lt alle wichtigen Machine Learning Algorithmen                                                 |
